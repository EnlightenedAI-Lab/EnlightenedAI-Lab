# Enlightened AI Lab â€” Project Index

This page lists all repositories maintained under the EnlightenedAI-Lab organization.  
Each project contributes to reflective stability, internal coherence, or frontier AI safety.

---

## ðŸ”µ Core Scientific Frameworks

### **RAA-Core**
Formal specification of the Reflective Alignment Architecture (RAA), including:
- Layer definitions (L1â€“L7)
- Reflective Duality Layer (RDL)
- PRD (Principle of Reflective Duality)
- Equations, diagrams, and the evolving scientific framework

Repo: https://github.com/EnlightenedAI-Lab/RAA-Core

---

## ðŸ”µ Evaluation & Diagnostics

### **LLM-Judge**
The practical evaluation system built on RAA.  
Measures:
- Forward vs reflective answers  
- MCIâ˜… (coherence stability)  
- Râˆ‡ (reflective improvement)  
- Drift and collapse signals  
- System-level dashboards

Repo: https://github.com/EnlightenedAI-Lab/LLM-Judge

---

## ðŸ”µ Interpretability & Systems Mapping

### **Mirror-H**
Interpretability and semantic stability framework.  
Tools for:
- Gyroscopic alignment model  
- Semantic drift visualization  
- Reflective mapping  
- Internal signal tracing  

Repo: https://github.com/EnlightenedAI-Lab/Mirror-H

---

## More Coming Soon
Additional research artifacts, datasets, diagrams, and scientific notes will be added as the lab work progresses.
