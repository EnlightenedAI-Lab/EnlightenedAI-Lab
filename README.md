<p align="center">
  <img src="./visuals/lab_banner.png"
       alt="Enlightened AI Research Lab Banner"
       width="100%" />
</p>

<p align="center">
  <a href="https://github.com/EnlightenedAI-Lab">
    <img src="https://img.shields.io/badge/Org-EnlightenedAI--Lab-black?logo=github" />
  </a>
  <img src="https://img.shields.io/badge/focus-reflective%20alignment-blue" />
  <img src="https://img.shields.io/badge/location-Montr%C3%A9al%2C%20Canada-lightgrey" />
  <a href="https://www.enlightenedai.ai">
    <img src="https://img.shields.io/badge/site-enlightenedai.ai-orange" />
  </a>
</p>

---

## ğŸ”¬ Research Focus

### **Reflective Alignment Architecture (RAA)**  
A multi-layer framework (L1â€“L7) designed to measure:

- internal coherence  
- value alignment  
- longitudinal drift  
- reflective self-correction  
- system-level stability  

---

### **Reflective Duality Layer (RDL)**  
The mathematical core of RAA.  
It compares:

- forward answer  
- reflective answer  
- Î” improvement (Râˆ‡)  
- coherence stability (MCIâ˜…)

These reveal whether the model becomes more coherent, more aligned, or more unstable under reflection.

---

### **Applied Evaluation Tools**

We develop:

- **LLM-Judge** â€” evaluation engine for coherence, drift, and stability  
- **Mirror-H** â€” interpretability lens for semantic & reflective mapping  
- **RAA-Core** â€” formal math, diagrams, and system definitions  

---

## ğŸ“‚ Key Projects

See **PROJECTS.md** for the full list.

- **LLM-Judge**  
  Multi-layer evaluation system for reflective coherence and drift.  
  https://github.com/EnlightenedAI-Lab/LLM-Judge

- **RAA-Core**  
  Formal definitions, math, and diagrams of the Reflective Alignment Architecture.  
  https://github.com/EnlightenedAI-Lab/RAA-Core

- **Mirror-H**  
  Interpretability toolkit for semantic stability and reflective mapping.  
  https://github.com/EnlightenedAI-Lab/Mirror-H  

---

## ğŸ“š Diagram Library

All diagrams used across RAA, RDL, and Mirror-H are indexed here:

â¡ï¸ **[DIAGRAMS.md](diagrams/DIAGRAMS.md)**  

The index includes thumbnails, captions, and source files.

---

## ğŸŒ Contact

**Website:** https://www.enlightenedai.ai  
**Email:** research@enlightenedai.ai  
**GitHub Organization:** https://github.com/EnlightenedAI-Lab  
**Location:** Montreal, Canada  
**ORCID:** https://orcid.org/0009-0006-5352-9727  

---

## ğŸ¤ Funders & Collaborators

We welcome collaboration with labs, institutions, and foundations working on:

- reflective alignment  
- stabilizing frontier AI systems  
- long-horizon behavioral prediction  
- foundational research in AI coherence  

> **To collaborate or support this work:**  
> research@enlightenedai.ai  

---

## ğŸ“œ License

All repositories under Enlightened AI Lab are released with open scientific intent.  
License terms may vary per project.
