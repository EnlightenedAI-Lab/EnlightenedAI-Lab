<p align="center">
  <img src="./visuals/lab_banner.png"
       alt="Enlightened AI Research Lab Banner"
       width="100%" />
</p>

<p align="center">
  <a href="https://github.com/EnlightenedAI-Lab">
    <img src="https://img.shields.io/badge/Org-EnlightenedAI--Lab-black?logo=github" />
  </a>
  <img src="https://img.shields.io/badge/focus-reflective%20alignment-1e88e5" />
  <img src="https://img.shields.io/badge/location-Montr%C3%A9al%2C%20Canada-lightgrey" />
  <a href="https://www.enlightenedai.ai">
    <img src="https://img.shields.io/badge/site-enlightenedai.ai-f57c00" />
  </a>
</p>

---

## ğŸ”¬ Research Focus

### **Reflective Alignment Architecture (RAA)**
A multi-layer reasoning and stability measurement framework (R1â€“R5 + L1â€“L7), designed to evaluate:

- Internal coherence  
- Moral & value alignment  
- Drift across long-horizon interactions  
- Reflective self-correction  
- System-level stability signals  

### **Reflective Duality Layer (RDL)**
The mathematical engine of RAA.

It compares:
- Forward answer  
- Reflective answer  
- Î” improvement vector (Râˆ‡)  
- Coherence stability metric (MCIâ˜…)  
- Reflective stability signal (Î¨)  

These form the **Reflective Stability Profile** used across RAA.

### **Applied Evaluation Tools**
We develop integrated evaluation systems:

- **LLM-Judge** â€” multi-layer reflective evaluation engine  
- **Mirror-H** â€” semantic stability & interpretability lens  
- **RAA-Core** â€” formal definitions, diagrams, equations  

---

## ğŸ“‚ Key Projects

### **LLM-Judge**
Multi-layer evaluation system for coherence, drift, and reflective stability.  
ğŸ”— https://github.com/EnlightenedAI-Lab/LLM-Judge

### **RAA-Core**
Formal definitions, math, structures, and diagrams of the Reflective Alignment Architecture (RAA).  
ğŸ”— https://github.com/EnlightenedAI-Lab/RAA-Core

### **Mirror-H**
Interpretability toolkit for semantic stability, gyroscopic alignment, and reflective mapping.  
ğŸ”— https://github.com/EnlightenedAI-Lab/Mirror-H

---

## ğŸ“š Diagram Library

All conceptual figures used in RAA are consolidated in:

â¡ï¸ **[DIAGRAMS.md](diagrams/DIAGRAMS.md)**

This index will later include thumbnails, descriptions, and links for every diagram in the architecture.

---

## ğŸŒ Contact

**Website:** https://www.enlightenedai.ai  
**Email:** research@enlightenedai.ai  
**GitHub:** https://github.com/EnlightenedAI-Lab  
**Location:** MontrÃ©al, Canada  
**ORCID:** https://orcid.org/0009-0006-5352-9727  

---

## ğŸ¤ Funders & Collaborators

We welcome collaboration with research labs, academic institutions, and foundations interested in:

- Reflective alignment & model stability  
- Long-horizon behavioural prediction  
- Instrumentation for safe reasoning  
- Scientific foundations of AI coherence  

> To collaborate or support this work:  
> ğŸ“§ **research@enlightenedai.ai**

Your name, institution, or partnership can be featured here.

---

## ğŸ“œ License

All Enlightened AI Lab repositories are released with open scientific intent.  
License terms may vary by project.
